{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kz4ALxGC0KnH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = pd.read_csv('/content/Housing.csv')\n",
        "X = data[['area', 'bathrooms', 'bedrooms']].values\n",
        "y = data['price'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gipotesa(X, w):\n",
        "    return X @ w"
      ],
      "metadata": {
        "id": "lcJV10tg0L_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(X, y, w):\n",
        "    m = len(y)\n",
        "    predictions = gipotesa(X, w)\n",
        "    return (1 / (2 * m)) * np.sum((predictions - y) ** 2)"
      ],
      "metadata": {
        "id": "odyDYV7R3Tve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_step(X, y, w, learning_rate):\n",
        "    m = len(y)\n",
        "    predictions = gipotesa(X, w)\n",
        "    gradient = (1 / m) * X.T @ (predictions - y)\n",
        "    w = w - learning_rate * gradient\n",
        "    return w"
      ],
      "metadata": {
        "id": "Ei99-aIi3fNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_linear_regression(X, y, learning_rate=0.01, num_iterations=1000):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    for _ in range(num_iterations):\n",
        "        w = gradient_descent_step(X, y, w, learning_rate)\n",
        "    return w"
      ],
      "metadata": {
        "id": "s7Oc1IYE35Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analytical_solution(X, y):\n",
        "    return np.linalg.inv(X.T @ X) @ X.T @ y"
      ],
      "metadata": {
        "id": "RTqHkhWA9DW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sklearn_solution(X, y):\n",
        "    model = LinearRegression().fit(X, y)\n",
        "    return model.coef_, model.intercept_"
      ],
      "metadata": {
        "id": "5w2hSOdo4fSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X = np.hstack([np.ones((X.shape[0], 1)), X])"
      ],
      "metadata": {
        "id": "mDbOkGOX_0xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "обучение\n",
        "\"\"\"\n",
        "w_gradient_descent = train_linear_regression(X, y)\n",
        "w_analytical = analytical_solution(X, y)\n",
        "coef_sklearn, intercept_sklearn = sklearn_solution(X[:, 1:], y)  # убираю столбик единиц\n",
        "\n",
        "\"\"\"\n",
        "прогнозирвание для сравнения\n",
        "\"\"\"\n",
        "y_pred_gradient_descent = gipotesa(X, w_gradient_descent)\n",
        "y_pred_analytical = gipotesa(X, w_analytical)\n",
        "\n",
        "\"\"\"\n",
        "делаем коэфициенты удобными для X\n",
        "\"\"\"\n",
        "coef_sklearn_full = np.hstack(([intercept_sklearn], coef_sklearn))\n",
        "\n",
        "y_pred_sklearn = gipotesa(X, coef_sklearn_full)\n",
        "\n",
        "\"\"\"\n",
        "результаты\n",
        "\"\"\"\n",
        "print(\"Градієнтний спуск:\", w_gradient_descent)\n",
        "print(\"Аналітичне рішення:\", w_analytical)\n",
        "print(\"Sklearn:\", coef_sklearn, intercept_sklearn)\n",
        "\n",
        "\"\"\"\n",
        "среднеквадратическая ошибка для каждого метода\n",
        "\"\"\"\n",
        "mse_gradient_descent = loss_func(X, y, w_gradient_descent)\n",
        "mse_analytical = loss_func(X, y, w_analytical)\n",
        "mse_sklearn = np.mean((y - y_pred_sklearn) ** 2) / 2\n",
        "\n",
        "print(\"MSE Градієнтний спуск:\", mse_gradient_descent)\n",
        "print(\"MSE Аналітичне рішення:\", mse_analytical)\n",
        "print(\"MSE Sklearn:\", mse_sklearn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d_ep8wt7oQe",
        "outputId": "30e8b1fb-5403-435c-ce43-f230dc47eee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Градієнтний спуск: [4766523.46205873  821199.26709864  695515.99623791  300296.28560637]\n",
            "Аналітичне рішення: [4766729.24770642  821214.14349519  695808.52272538  299983.57107963]\n",
            "Sklearn: [821214.14349519 695808.52272537 299983.57107963] 4766729.247706422\n",
            "MSE Градієнтний спуск: 895585103885.1151\n",
            "MSE Аналітичне рішення: 895585024988.6597\n",
            "MSE Sklearn: 895585024988.6597\n"
          ]
        }
      ]
    }
  ]
}